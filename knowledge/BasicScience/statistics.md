# 统计学

统计学是通过搜索, 整理, 分析, 描述`数据`等手段, 以达到推断所测对象的本质, 甚至`预测对象未来`的一门综合性科学。统计学用到了大量的数学及其它学科的专业知识, 其应用范围几乎覆盖了社会科学和自然科学的各个领域


## Bayesian Information Criterions 贝叶斯信息准则 BIC

主观贝叶斯派归纳理论的重要组成部分:
* 在不完全情报下, 对部分未知的状态用主观概率估计
* 然后用贝叶斯公式对发生概率进行修正
* 最后再利用期望值和修正概率做出最优决策



## Stein's Unbiased Risk Estimate (SURE)

是一种无偏估计方法, 是一种 `几乎任意的非线性有偏估计量` 的均方误差(MSE)的无偏估计量 , 提供了给定 Estimator 准确性的指示
这很重要, 因为 Estimator 的真实 MSE 是待估计的未知参数的函数, 因此无法准确观测 

简而言之: 对于未知随机变量预测不了其 均值, 方差, 但是能够预测其 MSE  

假设有一个随机 d 维向量 $\mu$, 其各个元素互相独立且均值为 $\mu_i, i=1,...,d$ , 其方差为 $\sigma^2$  
令随机变量 $\mu$ 的观测数据为 $x$ 定义其 estimator 为 $h(x)=x+g(x)$, $g(x)$ 是弱微分  

梳理一下
* $\mu$ 是随机变量, 其均值为 $\mu_i$ , 均值是未知的
* 定义一个 estimator h(x) 希望得到离真实值尽可能近的数据, 表现为 $h(x)=x+g(x)$, $x$ 是观测到的随机变量的数据, $g(x)$ 可以理解为 estimator 基于观测数据 x 的修正量
* 因为想要其结果最优, 我们定义一个优化函数还是会用到 随机变量的均值, 即这个优化函数里包括了未知量, 是无法直接进行优化甚至是计算的  

SURE 公式最重要的功能是, 他是$h(x)$ 的 MSE 的无偏估计, 即有  
$$E_\mu\{SURE(h)\}=MSE(h) = E_\mu||h(x)-\mu||^2$$

那么, 通过带入 SURE 公式, 即可在完全不知道随机变量均值的情况下实现对 estimator 的最优化  


有 SURE 的公式定义  $||\cdot||$ 是向量的模
$$SURE(h)=d\sigma^2+||g(x)||^2+2\sigma^2\sum_{i=1}^d\frac{\partial}{\partial x_i}g_i(x)=-d\sigma^2+||g(x)||^2+2\sigma^2\sum_{i=1}^d\frac{\partial}{\partial x_i}h_i(x)$$



